#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, LaserScan
from std_msgs.msg import String
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import PointStamped
from cv_bridge import CvBridge
import cv2
import numpy as np
import tf2_ros
import tf2_geometry_msgs
from collections import deque
import time

class ImprovedTreeDetector(Node):
    """
    Improved tree detector with better OpenCV processing to handle:
    - Multiple contour fragmentation
    - Spatial clustering of nearby detections
    - Temporal filtering for stable detections
    - Better shape and size validation
    """
    
    def __init__(self):
        super().__init__('improved_tree_detector')
        
        # Create OpenCV bridge
        self.bridge = CvBridge()
        self.scan = None
        
        # Subscribers
        self.image_sub = self.create_subscription(
            Image,
            'oak/rgb/image_raw',
            self.image_callback,
            10)
        
        self.scan_sub = self.create_subscription(
            LaserScan,
            '/scan',
            self.scan_callback,
            10)
        
        # Publishers
        self.tree_pub = self.create_publisher(String, '/detected_trees', 10)
        self.marker_pub = self.create_publisher(Marker, '/tree_markers', 10)
        self.debug_img_pub = self.create_publisher(Image, '/tree_detection/debug_image', 10)
        self.mask_img_pub = self.create_publisher(Image, '/tree_detection/mask_image', 10)
        self.processed_img_pub = self.create_publisher(Image, '/tree_detection/processed_image', 10)
        
        # TF setup
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        
        # IMPROVED DETECTION PARAMETERS
        # Color filtering
        self.brown_hsv_lower = np.array([8, 40, 20])    # Slightly wider range
        self.brown_hsv_upper = np.array([25, 255, 200]) # Include more brown variations
        
        # Size filtering (more restrictive)
        self.min_area = 300          # Increased minimum area
        self.max_area = 10000        # Maximum area to reject huge blobs
        self.min_aspect_ratio = 0.5  # Trees should be somewhat vertical
        self.max_aspect_ratio = 3.0  # But not too thin
        
        # Spatial clustering parameters
        self.cluster_distance = 100   # Pixels - merge detections within this distance
        self.min_contour_distance = 50  # Minimum distance between separate trees
        
        # Temporal filtering parameters
        self.detection_history = deque(maxlen=5)  # Keep last 5 frames
        self.stability_threshold = 3  # Detection must appear in 3/5 frames to be stable
        
        # LiDAR-based size validation
        self.expected_tree_width_meters = 0.15  # Expected tree diameter (15cm)
        self.size_tolerance = 0.5  # Allow 50% variation in expected size
        
        # Tracking
        self.stable_detections = []  # Current stable tree detections
        self.detection_count = 0
        self.frame_count = 0
        self.last_detection_frame = 0
        self.last_no_detection_log = 0
        self.detected_trees_positions = []
        
        self.get_logger().info('Improved Tree Detector initialized!')
        self.get_logger().info('Enhanced OpenCV processing with spatial clustering and temporal filtering')
        
    def scan_callback(self, msg):
        """Store LiDAR scan."""
        self.scan = msg
        
    def image_callback(self, msg):
        """Main detection callback with improved processing."""
        if self.scan is None:
            return
            
        try:
            self.frame_count += 1
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            
            # IMPROVED DETECTION PIPELINE
            trees = self.detect_trees_improved(cv_image)
            
            # Temporal filtering for stability
            stable_trees = self.apply_temporal_filtering(trees)
            
            if stable_trees:
                self.handle_trees_detected(cv_image, stable_trees)
            else:
                self.handle_no_trees_detected()
            
            # Enhanced debug visualization
            debug_img = self.create_enhanced_debug_image(cv_image, trees, stable_trees)
            self.debug_img_pub.publish(self.bridge.cv2_to_imgmsg(debug_img, encoding='bgr8'))
                
        except Exception as e:
            self.get_logger().error(f'Error in improved tree detection: {str(e)}')
    
    def detect_trees_improved(self, image):
        """
        IMPROVED DETECTION PIPELINE
        1. Better preprocessing
        2. Contour merging and clustering
        3. Shape and size validation
        4. Non-maximum suppression
        """
        # Convert to HSV
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # Create mask with improved morphological operations
        mask = cv2.inRange(hsv, self.brown_hsv_lower, self.brown_hsv_upper)
        
        # IMPROVEMENT 1: Better morphological operations
        # Remove noise with opening, then fill gaps with closing
        kernel_open = np.ones((3, 3), np.uint8)
        kernel_close = np.ones((7, 7), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel_close)
        
        # Publish mask for debugging
        self.mask_img_pub.publish(self.bridge.cv2_to_imgmsg(mask, encoding='mono8'))
        
        # Find contours
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return []
        
        # IMPROVEMENT 2: Filter contours by basic properties
        valid_contours = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if self.min_area <= area <= self.max_area:
                # Check aspect ratio
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = h / w if w > 0 else 0
                
                if self.min_aspect_ratio <= aspect_ratio <= self.max_aspect_ratio:
                    valid_contours.append(contour)
        
        if not valid_contours:
            return []
        
        # IMPROVEMENT 3: Convert to detection format and merge nearby detections
        raw_detections = []
        for contour in valid_contours:
            x, y, w, h = cv2.boundingRect(contour)
            area = cv2.contourArea(contour)
            center_x = x + w / 2
            center_y = y + h / 2
            
            raw_detections.append({
                'center_x': center_x,
                'center_y': center_y,
                'bbox': (x, y, w, h),
                'area': area,
                'contour': contour
            })
        
        # IMPROVEMENT 4: Spatial clustering to merge nearby detections
        clustered_detections = self.cluster_detections(raw_detections)
        
        # IMPROVEMENT 5: Validate detections using LiDAR data
        validated_detections = self.validate_detections_with_lidar(clustered_detections, image.shape[1])
        
        return validated_detections
    
    def cluster_detections(self, detections):
        """
        IMPROVEMENT: Cluster nearby detections that likely belong to the same tree
        """
        if not detections:
            return []
        
        clustered = []
        used = [False] * len(detections)
        
        for i, detection in enumerate(detections):
            if used[i]:
                continue
                
            # Start a new cluster
            cluster = [detection]
            used[i] = True
            
            # Find all detections within clustering distance
            for j, other_detection in enumerate(detections):
                if used[j]:
                    continue
                    
                distance = np.sqrt((detection['center_x'] - other_detection['center_x'])**2 + 
                                 (detection['center_y'] - other_detection['center_y'])**2)
                
                if distance <= self.cluster_distance:
                    cluster.append(other_detection)
                    used[j] = True
            
            # Merge cluster into single detection
            merged_detection = self.merge_cluster(cluster)
            clustered.append(merged_detection)
        
        return clustered
    
    def merge_cluster(self, cluster):
        """
        Merge a cluster of detections into a single detection
        """
        if len(cluster) == 1:
            return cluster[0]
        
        # Calculate merged bounding box
        min_x = min([det['bbox'][0] for det in cluster])
        min_y = min([det['bbox'][1] for det in cluster])
        max_x = max([det['bbox'][0] + det['bbox'][2] for det in cluster])
        max_y = max([det['bbox'][1] + det['bbox'][3] for det in cluster])
        
        merged_w = max_x - min_x
        merged_h = max_y - min_y
        merged_area = sum([det['area'] for det in cluster])
        
        return {
            'center_x': min_x + merged_w / 2,
            'center_y': min_y + merged_h / 2,
            'bbox': (min_x, min_y, merged_w, merged_h),
            'area': merged_area,
            'cluster_size': len(cluster)  # Track how many were merged
        }
    
    def validate_detections_with_lidar(self, detections, image_width):
        """
        IMPROVEMENT: Validate detection sizes using LiDAR distance data
        """
        validated = []
        
        for detection in detections:
            # Get LiDAR distance for this detection
            distance = self.get_lidar_distance(detection['center_x'], image_width)
            
            if distance is None:
                continue  # Skip if no valid LiDAR data
            
            # Calculate expected pixel size at this distance
            # Assuming camera FOV and resolution
            expected_pixel_width = self.calculate_expected_pixel_size(distance)
            actual_pixel_width = detection['bbox'][2]
            
            # Check if actual size is reasonable compared to expected
            size_ratio = actual_pixel_width / expected_pixel_width if expected_pixel_width > 0 else 0
            
            if (1 - self.size_tolerance) <= size_ratio <= (1 + self.size_tolerance):
                detection['distance'] = distance
                detection['size_ratio'] = size_ratio
                validated.append(detection)
            else:
                # Log rejected detections for debugging
                self.get_logger().debug(f'Rejected detection: size_ratio={size_ratio:.2f}, distance={distance:.2f}m')
        
        return validated
    
    def get_lidar_distance(self, center_x, image_width):
        """Get LiDAR distance for a pixel coordinate"""
        if self.scan is None:
            return None
            
        try:
            normalized_x = center_x / image_width
            angle = self.scan.angle_min + normalized_x * (self.scan.angle_max - self.scan.angle_min)
            index = int((angle - self.scan.angle_min) / self.scan.angle_increment)
            
            if 0 <= index < len(self.scan.ranges):
                distance = self.scan.ranges[index]
                if np.isfinite(distance) and self.scan.range_min <= distance <= self.scan.range_max:
                    return distance
        except Exception:
            pass
        return None
    
    def calculate_expected_pixel_size(self, distance):
        """Calculate expected pixel size of tree at given distance"""
        # Rough approximation - you may need to calibrate this
        # Assumes 60-degree horizontal FOV and 640 pixel width
        camera_fov = np.radians(60)  # 60 degrees in radians
        image_width_pixels = 640
        
        # Angular size of tree at distance
        angular_size = 2 * np.arctan(self.expected_tree_width_meters / (2 * distance))
        
        # Convert to pixels
        pixels_per_radian = image_width_pixels / camera_fov
        expected_pixels = angular_size * pixels_per_radian
        
        return max(expected_pixels, 10)  # Minimum 10 pixels
    
    def apply_temporal_filtering(self, current_detections):
        """
        IMPROVEMENT: Apply temporal filtering for stable detections
        """
        # Add current detections to history
        self.detection_history.append(current_detections)
        
        if len(self.detection_history) < self.stability_threshold:
            return []  # Not enough history yet
        
        # Find detections that appear consistently
        stable_detections = []
        
        for detection in current_detections:
            stability_count = 0
            
            # Check how many recent frames had a similar detection
            for past_detections in self.detection_history:
                for past_detection in past_detections:
                    distance = np.sqrt((detection['center_x'] - past_detection['center_x'])**2 + 
                                     (detection['center_y'] - past_detection['center_y'])**2)
                    
                    if distance <= self.cluster_distance:  # Same detection tolerance
                        stability_count += 1
                        break
            
            # If detection appears in enough frames, consider it stable
            if stability_count >= self.stability_threshold:
                detection['stability_count'] = stability_count
                stable_detections.append(detection)
        
        return stable_detections
    
    def handle_trees_detected(self, cv_image, trees):
        """Handle stable tree detections"""
        # Publish detection message
        tree_msg = String()
        tree_msg.data = f"trees_detected:{len(trees)}"
        self.tree_pub.publish(tree_msg)
        
        # Log with more detail about improvements
        if self.frame_count - self.last_detection_frame > 30:  # Every ~1 second
            self.detection_count += 1
            self.get_logger().info(f'ðŸŒ³ STABLE TREES DETECTED! Found {len(trees)} stable tree(s)')
            
            for i, tree in enumerate(trees):
                cluster_info = f" (merged from {tree.get('cluster_size', 1)} detections)" if tree.get('cluster_size', 1) > 1 else ""
                stability_info = f" stability:{tree.get('stability_count', 0)}/5"
                distance_info = f" distance:{tree.get('distance', 0):.2f}m" if tree.get('distance') else ""
                size_info = f" size_ratio:{tree.get('size_ratio', 0):.2f}" if tree.get('size_ratio') else ""
                
                self.get_logger().info(f'  Tree #{i+1}: {cluster_info}{stability_info}{distance_info}{size_info}')
            
            self.last_detection_frame = self.frame_count
            self.process_trees_for_markers(cv_image, trees)
    
    def handle_no_trees_detected(self):
        """Handle when no stable trees are detected"""
        if self.frame_count - self.last_no_detection_log > 90:  # Every ~3 seconds
            self.get_logger().info('No stable trees detected - scanning...')
            self.last_no_detection_log = self.frame_count
    
    def process_trees_for_markers(self, cv_image, trees):
        """Process trees for coordinate calculation and marker publishing"""
        for i, tree in enumerate(trees):
            world_coords = self.get_world_coordinates(tree['center_x'], cv_image.shape[1])
            
            if world_coords:
                lidar_x, lidar_y, map_x, map_y = world_coords
                
                if map_x is not None and map_y is not None:
                    self.publish_tree_marker(map_x, map_y, i)
                    
                    tree_position = (map_x, map_y)
                    if not self.is_duplicate_detection(tree_position):
                        self.detected_trees_positions.append(tree_position)
    
    def create_enhanced_debug_image(self, original_image, raw_detections, stable_detections):
        """
        IMPROVEMENT: Enhanced debug visualization showing processing steps
        """
        debug_img = original_image.copy()
        
        # Draw raw detections in red (before clustering/filtering)
        for detection in raw_detections:
            x, y, w, h = detection['bbox']
            cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Red
            cv2.putText(debug_img, "RAW", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        # Draw stable detections in green (after all filtering)
        for i, detection in enumerate(stable_detections):
            x, y, w, h = detection['bbox']
            cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 255, 0), 3)  # Green
            
            center_x, center_y = int(detection['center_x']), int(detection['center_y'])
            cv2.circle(debug_img, (center_x, center_y), 8, (0, 255, 0), -1)
            
            # Enhanced labels
            label = f"TREE #{i+1}"
            if detection.get('cluster_size', 1) > 1:
                label += f" (M:{detection['cluster_size']})"
            if detection.get('stability_count'):
                label += f" S:{detection['stability_count']}"
            
            cv2.putText(debug_img, label, (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # Add technical info
            tech_info = f"{detection['area']:.0f}pxÂ²"
            if detection.get('distance'):
                tech_info += f" {detection['distance']:.1f}m"
            cv2.putText(debug_img, tech_info, (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        # Enhanced status overlay
        cv2.putText(debug_img, f"ðŸŒ³ Raw detections: {len(raw_detections)} | Stable: {len(stable_detections)}", 
                    (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(debug_img, f"Frame: {self.frame_count} | History: {len(self.detection_history)}/5", 
                    (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        cv2.putText(debug_img, f"Total stable trees found: {len(self.detected_trees_positions)}", 
                    (10, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return debug_img
    
    # Keep existing methods for coordinate transformation and marker publishing
    def get_world_coordinates(self, center_x, image_width):
        """Convert pixel coordinates to world coordinates - same as before"""
        try:
            normalized_x = center_x / image_width
            angle = self.scan.angle_min + normalized_x * (self.scan.angle_max - self.scan.angle_min)
            index = int((angle - self.scan.angle_min) / self.scan.angle_increment)
            
            if index < 0 or index >= len(self.scan.ranges):
                return None
            
            distance = self.scan.ranges[index]
            if not np.isfinite(distance) or not (self.scan.range_min <= distance <= self.scan.range_max):
                return None
            
            point_lidar = PointStamped()
            point_lidar.header.frame_id = self.scan.header.frame_id
            point_lidar.header.stamp = self.scan.header.stamp
            point_lidar.point.x = distance * np.cos(angle)
            point_lidar.point.y = distance * np.sin(angle)
            point_lidar.point.z = 0.0
            
            map_coords = self.transform_to_map(point_lidar)
            if map_coords:
                map_x, map_y = map_coords
                return (point_lidar.point.x, point_lidar.point.y, map_x, map_y)
            else:
                return (point_lidar.point.x, point_lidar.point.y, None, None)
                
        except Exception as e:
            self.get_logger().error(f'Error getting world coordinates: {str(e)}')
            return None
    
    def transform_to_map(self, point_lidar):
        """Transform point to map frame - same as before"""
        try:
            timeout = rclpy.duration.Duration(seconds=0.1)
            if self.tf_buffer.can_transform('map', point_lidar.header.frame_id, rclpy.time.Time(), timeout=timeout):
                point_map = tf2_geometry_msgs.do_transform_point(
                    point_lidar,
                    self.tf_buffer.lookup_transform('map', point_lidar.header.frame_id, rclpy.time.Time(), timeout=timeout)
                )
                return (point_map.point.x, point_map.point.y)
            else:
                return None
        except Exception as e:
            return None
    
    def publish_tree_marker(self, map_x, map_y, tree_id):
        """Publish marker for RViz - same as before"""
        marker = Marker()
        marker.header.frame_id = 'map'
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = 'detected_trees'
        marker.id = tree_id
        marker.type = Marker.CYLINDER
        marker.action = Marker.ADD
        
        marker.pose.position.x = map_x
        marker.pose.position.y = map_y
        marker.pose.position.z = 0.5
        marker.pose.orientation.w = 1.0
        
        marker.scale.x = 0.25
        marker.scale.y = 0.25
        marker.scale.z = 1.0
        
        marker.color.r = 0.6
        marker.color.g = 0.3
        marker.color.b = 0.1
        marker.color.a = 0.9
        
        self.marker_pub.publish(marker)
    
    def is_duplicate_detection(self, new_position, threshold=0.5):
        """Check if tree position is too close to already detected trees - same as before"""
        new_x, new_y = new_position
        for existing_x, existing_y in self.detected_trees_positions:
            distance = np.sqrt((new_x - existing_x)**2 + (new_y - existing_y)**2)
            if distance < threshold:
                return True
        return False

def main(args=None):
    rclpy.init(args=args)
    
    try:
        tree_detector = ImprovedTreeDetector()
        tree_detector.get_logger().info('Starting improved tree detector with enhanced OpenCV processing...')
        tree_detector.get_logger().info('New debug topics: /tree_detection/mask_image, /tree_detection/processed_image')
        rclpy.spin(tree_detector)
    except KeyboardInterrupt:
        tree_detector.get_logger().info('Improved tree detector shutting down...')
    finally:
        if 'tree_detector' in locals():
            tree_detector.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
